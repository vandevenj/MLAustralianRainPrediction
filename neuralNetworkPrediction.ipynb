{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feed6f47-d5fd-46da-8ff3-130ab2661f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import trange\n",
    "\n",
    "%matplotlib inline\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# read in dataset with date column parsed\n",
    "df = pd.read_csv('cleanedWeatherAUS.csv',\n",
    "    parse_dates=['Date'],\n",
    "    index_col='Date')\n",
    "\n",
    "\n",
    "y = df['RainTomorrow']\n",
    "xs = df[df.columns.difference(['RainTomorrow'])]\n",
    "\n",
    "# split dataset, 80% train 20% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data_x, test_data_x, train_data_y, test_data_y = train_test_split(xs, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d38b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "train_data = data_utils.TensorDataset(torch.Tensor(np.array(train_data_x)), torch.Tensor(np.array(train_data_y)))\n",
    "test_data = data_utils.TensorDataset(torch.Tensor(np.array(test_data_x)), torch.Tensor(np.array(test_data_y)))\n",
    "\n",
    "train_mean = [4.3997e+00, 4.5145e+00, 5.7088e+00, 4.7249e+01, 6.8562e+01, 2.4562e+01,\n",
    "        2.3394e+01, 1.1880e+01, 1.0152e+03, 1.0178e+03, 1.5625e-01, 1.5844e+00,\n",
    "        7.9468e+00, 2.2276e+01, 1.6602e+01, 8.0469e+00, 8.4531e+00, 8.9844e+00,\n",
    "        3.9217e+01, 1.8432e+01, 1.4453e+01]\n",
    "train_std = [ 2.2576,  2.1151,  2.2341, 17.3860, 19.0654, 15.3591,  6.0735,  5.6280,\n",
    "         6.5641,  6.8042,  0.3660,  5.4969,  2.4661,  5.3701,  5.4730,  4.1113,\n",
    "         4.8269,  4.5233, 13.8603, 10.3934, 10.9137]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize((train_mean, ), (train_std, ))\n",
    "])\n",
    "\n",
    "train_data.transform = transform\n",
    "test_data.transform = transform\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=True) \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7796f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "xs, labels = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5084a098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNClassifier(\n",
      "  (fc1): Linear(in_features=21, out_features=10, bias=True)\n",
      "  (act): Tanh()\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (log_softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 21\n",
    "hidden_size = 10 \n",
    "output_size = 2 \n",
    "\n",
    "\n",
    "import math \n",
    "\n",
    "class NNClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # layer 1\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # activation function\n",
    "        self.act = torch.nn.Tanh()        \n",
    "        \n",
    "        # layer 2 \n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "            \n",
    "        # layer 3 \n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)            \n",
    "            \n",
    "        # layer 4\n",
    "        self.fc4 = torch.nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # output\n",
    "        self.log_softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # output after layer 1\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # apply activation function\n",
    "        x = self.act(x)\n",
    "        \n",
    "        # output after layer 2\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # apply activation function\n",
    "        x = self.act(x)\n",
    "        \n",
    "        # output after layer 3\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # apply activation function\n",
    "        x = self.act(x)\n",
    "        \n",
    "        # output after layer 4\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        # output after applying softmax\n",
    "        return self.log_softmax(x)\n",
    "\n",
    "model = NNClassifier().to(DEVICE)\n",
    "\n",
    "# sanity check\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fe390f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, model, device, optimizer, log_interval, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    counter = []\n",
    "    cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for i, (img, label) in enumerate(train_loader):\n",
    "        img, label = img.to(device), label.to(device).long()\n",
    "        \n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # run forward on image data \n",
    "        outputs = model.forward(img)\n",
    "\n",
    "        # compute loss\n",
    "        loss = cross_entropy_loss(outputs, label)\n",
    "        loss.backward()\n",
    "\n",
    "        # adjust learning weights\n",
    "        optimizer.step()\n",
    "               \n",
    "        # Record training loss every log_interval and keep counter of total training images seen\n",
    "        if (i+1) % log_interval == 0:\n",
    "            losses.append(loss.item())\n",
    "            counter.append(\n",
    "                (i * batch_size) + img.size(0) + epoch * len(train_loader.dataset))\n",
    "\n",
    "    return losses, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d870aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(test_loader, train_loader, model, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    train_num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (features, label) in enumerate(test_loader):\n",
    "            features, label = features.to(device), label.to(device)\n",
    "\n",
    "            # ------------------\n",
    "            # Write your implementation here.\n",
    "            \n",
    "            output = model.forward(features)\n",
    "            pred = output.argmax(dim=1) \n",
    "            for iii in range(0, len(pred)):\n",
    "                num_correct = num_correct + 1 if pred[iii] == label[iii] else num_correct + 0\n",
    "                test_loss = test_loss + 0 if pred[iii] == label[iii] else test_loss + 1\n",
    "        for i, (features, label) in enumerate(train_loader):\n",
    "            features, label = features.to(device), label.to(device)\n",
    "\n",
    "            # ------------------\n",
    "            # Write your implementation here.\n",
    "            \n",
    "            output = model.forward(features)\n",
    "            pred = output.argmax(dim=1) \n",
    "            for iii in range(0, len(pred)):\n",
    "                train_num_correct = train_num_correct + 1 if pred[iii] == label[iii] else train_num_correct + 0\n",
    "                # _loss = test_loss + 0 if pred[iii] == label[iii] else test_loss + 1\n",
    "\n",
    "            # ------------------\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, num_correct, train_num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a6a9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  33%|█████████████████████████▋                                                   | 1/3 [00:23<00:47, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7751679032314779\n",
      "Train counter: 0.775981503947114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:52<00:26, 26.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7751679032314779\n",
      "Train counter: 0.775981503947114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [01:20<00:00, 26.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7751679032314779\n",
      "Train counter: 0.775981503947114\n",
      "Test accuracy: 0.7751679032314779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "lr = 0.01\n",
    "max_epochs=3\n",
    "gamma = 0.95\n",
    "\n",
    "# Recording data\n",
    "log_interval = 100\n",
    "\n",
    "# Instantiate optimizer (model was created in previous cell)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_correct = []\n",
    "for epoch in trange(max_epochs, leave=True, desc='Epochs'):\n",
    "    train_loss, counter = train_one_epoch(train_loader, model, DEVICE, optimizer, log_interval, epoch)\n",
    "    test_loss, num_correct, train_num_correct = test_one_epoch(test_loader, train_loader, model, DEVICE)\n",
    "\n",
    "    # Record results\n",
    "    train_losses.extend(train_loss)\n",
    "    train_counter.extend(counter)\n",
    "    test_losses.append(test_loss)\n",
    "    test_correct.append(num_correct)\n",
    "    print(f\"Test accuracy: {num_correct/len(test_loader.dataset)}\")\n",
    "    \n",
    "    print(f\"Train counter: {train_num_correct/len(train_loader.dataset)}\")\n",
    "\n",
    "print(f\"Test accuracy: {test_correct[-1]/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Draw training loss curve\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(train_counter, train_losses, label='Train loss')\n",
    "plt.plot([i * len(train_loader.dataset) for i in range(1, max_epochs + 1)], \n",
    "         test_losses, label='Test loss', marker='o')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.title('Loss curve', fontsize=24)\n",
    "plt.xlabel('Number of training examples seen', fontsize=16)\n",
    "plt.ylabel('NLL', fontsize=16)\n",
    "plt.legend(loc='upper right', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
